{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    " \n",
    "# selenium import\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import urllib.request\n",
    "\n",
    "from io import BytesIO\n",
    "# from openpyxl import Workbook\n",
    "# from openpyxl.drawing.image import Image\n",
    "\n",
    "from upload_data import *\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"window-size=1920x1080\") # 화면크기(전체화면)\n",
    "options.add_argument(\"window-size=2560x1440\")\n",
    "options.add_argument(\"disable-gpu\")\n",
    "options.add_argument(\"disable-infobars\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument('--no-sandbox')\n",
    "# options.add_argument('--headless')  # 브라우저를 숨기는 옵션 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"C:/Users/tips_workstation2/Downloads/meta_출산-유아용품_50000614_20240816-18_13_24.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:/Users/tips_workstation2/Downloads/meta_출산-유아용품_50000614_20240816-18_13_24.csv.', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset= ['product_names','product_urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls = data['product_urls'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# except_data = pd.read_csv(\"C:/Users/tips_workstation2/Desktop/C_Review/df_except_url.csv\")\n",
    "# except_data = except_data['except_url'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver_path = r'C:/Users/tips_workstation2/Desktop/new_crawler/chromedriver-win64/chromedriver.exe'\n",
    "service = Service(executable_path=chrome_driver_path)\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# URL 리스트\n",
    "# urls = ['https://cr.shopping.naver.com/adcr.nhn?x=DwrCo1vLLbjpUak5juPgtf%2F%2F%2Fw%3D%3DsZtY5NFjXAfsivixZsTQomb%2BcLFA0Qj567HSfc9VC02OedMUWqnXIzj66FooS5oY%2FjBHJ8G0YZYRcccyU4ef9Gf8FHPDjn2BfnATINGE76fDbec32ynutqa9vppdSodNmg4Jh40wBIvXqZKMKJ%2BTVzMu1rI7y%2Bnxga7qkc20jAaEHS16Mm4swTlRWNG5xgFwbbzflVy0wI0y%2FZd91tQThG5vMghwznzbbU4PEkj4x778V0MIubreMfYn18wDP4TWofwtKKs9UXD0b%2BuMkAbBKR6Tq%2FbD2MGowZHhNOyBhpCeUgj7JhipZW7dJJfFyMQl0M6N8r%2B4R2IFQhbBQnBk56Vpd6HkF4PlrVyRjT1YfTWzXu9%2FbTMMj8ShqDHul8W1pZFb3q7ed3JQofxiIa%2F5WUUwWXwjJy%2Ff3jjuntaq%2BPYVx3qD225EaXn4cT7PNXiT4OiwvCtxrEMi02%2Brr8wku4zdQzQ6h%2Bx0nC1fw5saLnpP7mznP4AC3nBVLt9BYjX0xINy%2BaWdOz5NwdOp8Vl8G9KKqzblhPlZKVIDKnHwXy02MmdE970Z%2BYe%2Bg4Nl6BjN1sG3XYgKyOfWh13MoBcHdJ1VnRdYExPsTAl3EvuAdwXtTMmE6D6k7Fn1YO%2BPHYVGk9bCYs7o1a2MZxG3O5EqLl5y8sARekz3cqx4uaUskJFYNUJgJp6CUXauCvW7Y5AjN&nvMid=86362778320&catId=50003455']\n",
    "urls = product_urls\n",
    "\n",
    "exception_urls = []\n",
    "\n",
    "# dataframes = {}\n",
    "# folder_paths = []\n",
    "\n",
    "# 통합리스트 초기화\n",
    "all_brand_names = []\n",
    "all_product_names = []\n",
    "all_write_dt_lst = []\n",
    "all_rating_lst = []\n",
    "all_content_lst = []\n",
    "\n",
    "count = 0\n",
    "# URL에서 데이터 수집\n",
    "for url in tqdm(urls):\n",
    "    driver.get(url)\n",
    "    actual_url = driver.current_url\n",
    "    print(actual_url)\n",
    "\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 현재 url이 두가지로 시작하지 않으면 예외처리 후 다음 url로 넘김\n",
    "    if not (actual_url.startswith('https://brand') or actual_url.startswith('https://smartstore')) :\n",
    "        exception_urls.append(actual_url)\n",
    "        continue\n",
    "\n",
    "    # 각 url 마다 수집할 list 초기화\n",
    "    brand_name = []\n",
    "    product_name = []\n",
    "    write_dt_lst = []\n",
    "    rating_lst = []\n",
    "    content_lst = []\n",
    "\n",
    "    # 브랜드명과 상품명을 수집 -> 사이트마다 브랜드명이 들어가는 방법이 크게 4가지로 보임\n",
    "    # try: \n",
    "    #     try:\n",
    "    #         brand_element = driver.find_element(By.CSS_SELECTOR, '#pc-storeNameWidget > div > div > a > img')\n",
    "    #         brand = brand_element.get_attribute('alt')\n",
    "    #     except:\n",
    "    #         try:\n",
    "    #             brand_element = driver.fine_element(By.CSS_SELECTOR, \"#pc-gnbWidget > div > div > div._1G2E7OXbG3 > div._3aNsjos9K5 > h1 > a > img\")\n",
    "    #             brand = brand_element.get_attribute('alt')\n",
    "    #         except:\n",
    "    #             try:\n",
    "    #                 brand_element = driver.find_element(By.CSS_SELECTOR, \"#pc-storeNameWidget > div > div > a > span\")\n",
    "    #                 brand = brand_element.text\n",
    "    #             except:   \n",
    "    #                 brand_element = driver.find_element(By.CSS_SELECTOR, \"#pc-gnbWidget > div > div > div._1G2E7OXbG3 > div._3aNsjos9K5 > h1 > a > span\")\n",
    "    #                 brand = brand_element.text\n",
    "    #                 try :\n",
    "    #                     brand_element = driver.find_element(By.CSS_SELECTOR, \"#pc-gnbWidget > div > div > div._1G2E7OXbG3 > div._3aNsjos9K5 > h1 > a > img\")\n",
    "    #                     brand = brand_element.get_attribute('alt')\n",
    "    #                 except Exception as e:\n",
    "    #                     print(f\"브랜드명 수집 실패 : {e}\")\n",
    "        \n",
    "    #     #content > div > div._2-I30XS1lA > div._2QCa6wHHPy > fieldset > div._3k440DUKzy > div._1eddO7u4UC > h3\n",
    "    #     # product = driver.find_element(By.XPATH, '//*[@id=\"content\"]/div/div[2]/div[2]/fieldset/div[1]/div[1]/h3').text\n",
    "    #     product = driver.find_element(By.CSS_SELECTOR, '#content > div > div._2-I30XS1lA > div._2QCa6wHHPy > fieldset > div._3k440DUKzy > div._1eddO7u4UC > h3').text\n",
    "    #     # driver.execute_script(\"arguments[0].scrollIntoView(true);\", product)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"상품명 수집 실패 : {e}\")\n",
    "    #     exception_urls.append(url)\n",
    "    #     continue\n",
    "     #pc-gnbWidget > div > div > div._1G2E7OXbG3 > div._3aNsjos9K5 > h1 > a > img\n",
    "\n",
    " \n",
    "    try:\n",
    "        brand_element = driver.find_element(By.CSS_SELECTOR, '#pc-storeNameWidget > div > div > a > img')\n",
    "        brand = brand_element.get_attribute('alt')\n",
    "    except:\n",
    "        try:\n",
    "            brand_element = driver.fine_element(By.CSS_SELECTOR, \"#pc-gnbWidget > div > div > div._1G2E7OXbG3 > div._3aNsjos9K5 > h1 > a > img\")\n",
    "            brand = brand_element.get_attribute('alt')\n",
    "        except:\n",
    "            try:\n",
    "                brand_element = driver.find_element(By.CSS_SELECTOR, \"#pc-storeNameWidget > div > div > a > span\")\n",
    "                brand = brand_element.text\n",
    "            except:   \n",
    "                brand_element = driver.find_element(By.CSS_SELECTOR, \"#pc-gnbWidget > div > div > div._1G2E7OXbG3 > div._3aNsjos9K5 > h1 > a > span\")\n",
    "                brand = brand_element.text\n",
    "                try :\n",
    "                    brand_element = driver.find_element(By.CSS_SELECTOR, \"#pc-gnbWidget > div > div > div._1G2E7OXbG3 > div._3aNsjos9K5 > h1 > a > img\")\n",
    "                    brand = brand_element.get_attribute('alt')\n",
    "                except Exception as e:\n",
    "                    print(f\"브랜드명 수집 실패 : {e}\")\n",
    "    \n",
    "    # 마우스 scroll을 통해 가장 마지막 페이지까지 내려줌\n",
    "    scroll_location = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        time.sleep(10)\n",
    "        scroll_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if scroll_location == scroll_height:\n",
    "            break\n",
    "        else:\n",
    "            scroll_location = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    try:\n",
    "        product = driver.find_element(By.CSS_SELECTOR, '#_productFloatingTab > div > div.XYLPnZFSI9 > strong').text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"상품명 수집 실패 : {e}\")\n",
    "        exception_urls.append(url)\n",
    "        continue\n",
    "\n",
    "    # 긁은 상품명에 마지막에 띄어쓰기가 들어가는 경우 경로를 찾지 못하는 에러 발생함\n",
    "    sanitized_product = product.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\":\", \"_\").replace(\"+\", \"_\")\n",
    "    folder_name = sanitized_product\n",
    "    # folder_name = f\"{product}\"\n",
    "    folder_path = os.path.join(f'C:/Users/tips_workstation2/Desktop/C_Review/', folder_name) # local_path\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # 리뷰 버튼 클릭\n",
    "        #_productFloatingTab > div > div._27jmWaPaKy._1dDHKD1iiX > ul > li:nth-child(2) > a \n",
    "        #content > div > div.z7cS6-TO7X > div._27jmWaPaKy > ul > li:nth-child(2) > a\n",
    "        try : \n",
    "            driver.find_element(By.CSS_SELECTOR, '#_productFloatingTab > div > div._27jmWaPaKy._1dDHKD1iiX > ul > li:nth-child(2) > a').click()\n",
    "            time.sleep(3)\n",
    "        except :\n",
    "            driver.find_element(By.CSS_SELECTOR, '#content > div > div.z7cS6-TO7X > div._27jmWaPaKy > ul > li:nth-child(2) > a').click()\n",
    "            time.sleep(3)\n",
    "\n",
    "        # 최신순 버튼 클릭  \n",
    "        driver.find_element(By.CSS_SELECTOR, '#REVIEW > div > div._2LvIMaBiIO > div._2LAwVxx1Sd > div._1txuie7UTH > ul > li:nth-child(2) > a').click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    # 리뷰 버튼이나 최신순 버튼이 없으면 리뷰가 없을 가능성이 높음으로 다음 url로 넘어가게 함\n",
    "    except Exception as e:\n",
    "        print(f\"최신순 버튼 클릭 실패: {e}\")\n",
    "        exception_urls.append(actual_url)\n",
    "        continue\n",
    "\n",
    "    # 현재 페이지\n",
    "    page_num = 1\n",
    "    # 다음 버튼 css_element의 nth_child({page_ctl}) 부분\n",
    "    page_ctl = 3\n",
    "\n",
    "    while True:\n",
    "        print(f'start: {page_num} page 수집 중, page_ctl: {page_ctl}')\n",
    "\n",
    "        # 리뷰가 있는지 확인\n",
    "        reviews = soup.findAll('li', {'class': 'BnwL_cs1av _nlog_click _nlog_impression_element'})\n",
    "\n",
    "        # 최신순 버튼은 눌렀으나 여기에 리뷰가 없을 가능성을 생각해서 로직 하나 추가\n",
    "        if not reviews:\n",
    "            print(\"리뷰가 없습니다. 다음 URL로 넘어갑니다.\")\n",
    "            exception_urls.append(actual_url)\n",
    "            break \n",
    "\n",
    "        for review in range(len(reviews)):\n",
    "            # 4-1. 리뷰 작성 일자 수집\n",
    "            write_dt_raw = reviews[review].findAll('span', {'class': '_2L3vDiadT9'})[0].get_text()\n",
    "            write_dt = datetime.strptime(write_dt_raw, '%y.%m.%d.').strftime('%Y%m%d')\n",
    "\n",
    "            # 4-2. 평점 수집\n",
    "            rating = reviews[review].findAll('em', {'class': '_15NU42F3kT'})[0].get_text()\n",
    "\n",
    "            # 4-3. 리뷰 내용 수집\n",
    "            review_content_raw = reviews[review].findAll('div', {'class': '_1kMfD5ErZ6'})[0].find('span', {'class': '_2L3vDiadT9'}).get_text()\n",
    "            review_content = re.sub(' +', ' ', re.sub('\\n', ' ', review_content_raw))\n",
    "\n",
    "            # 4-4. 리뷰 이미지 수집 (첫 페이지만 수집)\n",
    "            if page_num == 1:\n",
    "                # review_image_tag = reviews[review].find('img', {'class': '_3Lp-477Dqi'})\n",
    "                review_image_tag = reviews[review].find('span', {'class': '_1DOkWFrX74'})               \n",
    "                if review_image_tag:\n",
    "                    try : \n",
    "                        review_image_tags = review_image_tag.find_all('img')\n",
    "                        if review_image_tags:                          \n",
    "                            review_image_link = review_image_tags[0]['data-src']\n",
    "                            print(f'Review Image Link : {review_image_link}')\n",
    "                            review_image_link = review_image_link.replace('https', 'http')\n",
    "                            opener = urllib.request.build_opener()\n",
    "                            opener.addheaders = [('User-Agent', 'Mozilla/5.0')]\n",
    "                            urllib.request.install_opener(opener)\n",
    "                            local_img_path = os.path.join(folder_path, f'{count}.jpg')\n",
    "                            urllib.request.urlretrieve(review_image_link, local_img_path) # local 저장 path\n",
    "                            count += 1\n",
    "\n",
    "                            # s3에도 업로드\n",
    "                            ecommerce = 'naver'\n",
    "                            crawling_type = 'review'\n",
    "                            category = '출산-육아용품'         # 여기부터 변경\n",
    "                            search_type = 'ctg4_ID'\n",
    "                            file_type = 'image'\n",
    "                            keyword = '50000614'\n",
    "                            jpg_fullname = f\"{folder_name}/{count}\"\n",
    "                            jpg_file_path = local_img_path\n",
    "                            \n",
    "                            save_review_image_data(ecommerce, crawling_type, category, search_type, file_type, jpg_file_path, jpg_fullname, keyword)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"src 수집 실패 : {e}\")\n",
    "                        break\n",
    "            else:\n",
    "                review_image = ''\n",
    "\n",
    "            # 4-5. 수집 데이터 리스트 저장\n",
    "            brand_name.append(brand)\n",
    "            product_name.append(product)    \n",
    "            write_dt_lst.append(write_dt)\n",
    "            rating_lst.append(rating)\n",
    "            content_lst.append(review_content)\n",
    "\n",
    "        # 크롤링 중지 기준 날짜 설정\n",
    "        # 리뷰 수집 일자 기준 데이터 확인(페이지 긁고 최근 6개월 날짜 이전이면 break)\n",
    "        date_cut = (datetime.now() - timedelta(days=180)).strftime('%Y%m%d')\n",
    "        if write_dt_lst[-1] < date_cut:\n",
    "            break\n",
    "\n",
    "        # 리뷰 수집이 덜 되었으면 다음 페이지로 넘어가서 다시 긁음\n",
    "        # brandstore의 경우 페이지 넘김 부분이 10 페이지 이후에 다음 버튼을 한번 눌러줘야 함\n",
    "        if actual_url.startswith('https://brand'):\n",
    "            if page_num % 10 == 0:\n",
    "                # 다음 버튼 클릭\n",
    "                try:\n",
    "                    next_button = driver.find_element(By.CSS_SELECTOR, \"#REVIEW > div > div._2LvIMaBiIO > div._2g7PKvqCKe > div > div > a.fAUKm1ewwo._2Ar8-aEUTq._nlog_click\")\n",
    "                    next_button.click()\n",
    "                    time.sleep(3)  # 페이지 로딩 시간을 고려하여 잠시 대기\n",
    "                except Exception as e:\n",
    "                    print(f\"다음 버튼 클릭 실패: {e}\")\n",
    "                    break\n",
    "                # page_ctl 초기화\n",
    "                page_ctl = 3\n",
    "            else:\n",
    "                try:\n",
    "                    driver.find_element(By.CSS_SELECTOR, f'#REVIEW > div > div._2LvIMaBiIO > div._2g7PKvqCKe > div > div > a:nth-child({page_ctl})').click()\n",
    "                    time.sleep(3)\n",
    "                except Exception as e:\n",
    "                    print(f\"페이지 버튼 클릭 실패: {e}\")\n",
    "                    break\n",
    "                page_ctl += 1\n",
    "        # smartstore의 경우 페이지 넘김 부분이 6 페이지 이후 고정되기 때문에, 계속 다음 버튼만 누름\n",
    "        elif actual_url.startswith('https://smartstore'):\n",
    "            try:\n",
    "                next_button = driver.find_element(By.CSS_SELECTOR, \"#REVIEW > div > div._2LvIMaBiIO > div._2g7PKvqCKe > div > div > a.fAUKm1ewwo._2Ar8-aEUTq._nlog_click\")\n",
    "                next_button.click()\n",
    "                time.sleep(4)  # 페이지 로딩 시간을 고려하여 잠시 대기\n",
    "            except Exception as e:\n",
    "                print(f\"다음 버튼 클릭 실패: {e}\")\n",
    "                break\n",
    "\n",
    "        page_num += 1\n",
    "\n",
    "    # # 각 url마다 수집되는 list들을 df로 생성\n",
    "    # df = pd.DataFrame({\n",
    "    #     'brand_name': brand_name,\n",
    "    #     'product_name': product_name,\n",
    "    #     'write_dt_lst': write_dt_lst,\n",
    "    #     'rating_lst': rating_lst,\n",
    "    #     'content_lst': content_lst\n",
    "    # })\n",
    "\n",
    "    # 구문 가장 밖에 있는 list에 모든 값들을 extend -> url 순서대로 모든 정보가 차곡자곡 쌓임\n",
    "    all_brand_names.extend(brand_name)\n",
    "    all_product_names.extend(product_name)\n",
    "    all_write_dt_lst.extend(write_dt_lst)\n",
    "    all_rating_lst.extend(rating_lst)\n",
    "    all_content_lst.extend(content_lst)\n",
    "\n",
    "# 모아진 모든 list를 df화\n",
    "df_all = pd.DataFrame({\n",
    "    'brand_name' : all_brand_names,\n",
    "    'product_name' : all_product_names,\n",
    "    'write_dt_lst' : all_write_dt_lst,\n",
    "    'rating_lst' : all_rating_lst,\n",
    "    'content_lst' : all_content_lst\n",
    "})\n",
    "\n",
    "# ====================save to S3 folder=========================\n",
    "# 카테고리마다 변경\n",
    "ecommerce = 'naver'\n",
    "crawling_type = 'review'\n",
    "category = '출산-육아용품'\n",
    "search_type = 'ctg4_ID' # or 'ctg4_ID'\n",
    "file_type = 'reviews'\n",
    "keyword = '50000614'\n",
    "save_review_data(df_all, ecommerce, crawling_type, category, search_type, file_type, keyword)\n",
    "\n",
    "print('done')\n",
    "driver.quit() \n",
    "\n",
    "\n",
    "if exception_urls:\n",
    "    print(f\"예외 URL ({len(exception_urls)}개):\")\n",
    "    for exception_url in exception_urls:\n",
    "        print(exception_url)\n",
    "else:\n",
    "    print(\"예외 URL 없음\")\n",
    "\n",
    "df_except_url = pd.DataFrame({\n",
    "    'except_url' : exception_urls})\n",
    "\n",
    "df_except_url.to_csv(f'C:/Users/tips_workstation2/Desktop/C_Review/df_except_url_{keyword}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_name</th>\n",
       "      <th>write_dt_lst</th>\n",
       "      <th>rating_lst</th>\n",
       "      <th>content_lst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>질마재 농장</td>\n",
       "      <td>[질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...</td>\n",
       "      <td>20240816</td>\n",
       "      <td>4</td>\n",
       "      <td>고소하고 맛있어요!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>질마재 농장</td>\n",
       "      <td>[질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...</td>\n",
       "      <td>20240816</td>\n",
       "      <td>4</td>\n",
       "      <td>고소하고 맛있어요!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>질마재 농장</td>\n",
       "      <td>[질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...</td>\n",
       "      <td>20240815</td>\n",
       "      <td>5</td>\n",
       "      <td>다른 첨가물도 없고 곡물 그 자체라 좋아요. 아이도 잘 먹어서 여러개 쟁여놨어요~ㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>질마재 농장</td>\n",
       "      <td>[질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...</td>\n",
       "      <td>20240815</td>\n",
       "      <td>5</td>\n",
       "      <td>첨가물도 없고 곡물 그 자체라 좋아요. 아이도 잘먹어요ㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>질마재 농장</td>\n",
       "      <td>[질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...</td>\n",
       "      <td>20240815</td>\n",
       "      <td>5</td>\n",
       "      <td>다른것보다 유난히 이걸좋아하네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52628</th>\n",
       "      <td>그린원푸드</td>\n",
       "      <td>그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]</td>\n",
       "      <td>20240202</td>\n",
       "      <td>5</td>\n",
       "      <td>종류별로 구매했어요 다먹으면 재구매하려구요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52629</th>\n",
       "      <td>그린원푸드</td>\n",
       "      <td>그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]</td>\n",
       "      <td>20240202</td>\n",
       "      <td>5</td>\n",
       "      <td>아기가 좋아해요 개인적으로 단호박 흑임자가 좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52630</th>\n",
       "      <td>그린원푸드</td>\n",
       "      <td>그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]</td>\n",
       "      <td>20240202</td>\n",
       "      <td>5</td>\n",
       "      <td>유기농에 다른 첨가물 없이 건강한 맛이예요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52631</th>\n",
       "      <td>그린원푸드</td>\n",
       "      <td>그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]</td>\n",
       "      <td>20240202</td>\n",
       "      <td>5</td>\n",
       "      <td>지인에게 받아 한봉 먹여봤는데 아기도 잘먹고 한입 쏙이라 손이 지저분해지지 않아 좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52632</th>\n",
       "      <td>그린원푸드</td>\n",
       "      <td>그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]</td>\n",
       "      <td>20240125</td>\n",
       "      <td>5</td>\n",
       "      <td>소근육 발달에 좋대서 주문했는데 아기도 잘 먹고 좋아요^^</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52633 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand_name                                       product_name  \\\n",
       "0         질마재 농장  [질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...   \n",
       "1         질마재 농장  [질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...   \n",
       "2         질마재 농장  [질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...   \n",
       "3         질마재 농장  [질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...   \n",
       "4         질마재 농장  [질마재농장]유기농 쌀과자 백미 시리얼 120g 외11종 [원산지:국산(전라북도 고...   \n",
       "...          ...                                                ...   \n",
       "52628      그린원푸드          그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]   \n",
       "52629      그린원푸드          그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]   \n",
       "52630      그린원푸드          그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]   \n",
       "52631      그린원푸드          그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]   \n",
       "52632      그린원푸드          그린원푸드 유기농 옹알이 쌀과자 30g 5+1 (1개랜덤) [원산지:국산]   \n",
       "\n",
       "      write_dt_lst rating_lst  \\\n",
       "0         20240816          4   \n",
       "1         20240816          4   \n",
       "2         20240815          5   \n",
       "3         20240815          5   \n",
       "4         20240815          5   \n",
       "...            ...        ...   \n",
       "52628     20240202          5   \n",
       "52629     20240202          5   \n",
       "52630     20240202          5   \n",
       "52631     20240202          5   \n",
       "52632     20240125          5   \n",
       "\n",
       "                                            content_lst  \n",
       "0                                            고소하고 맛있어요!  \n",
       "1                                            고소하고 맛있어요!  \n",
       "2        다른 첨가물도 없고 곡물 그 자체라 좋아요. 아이도 잘 먹어서 여러개 쟁여놨어요~ㅎ  \n",
       "3                       첨가물도 없고 곡물 그 자체라 좋아요. 아이도 잘먹어요ㅎ  \n",
       "4                                     다른것보다 유난히 이걸좋아하네요  \n",
       "...                                                 ...  \n",
       "52628                           종류별로 구매했어요 다먹으면 재구매하려구요  \n",
       "52629                       아기가 좋아해요 개인적으로 단호박 흑임자가 좋아요  \n",
       "52630                           유기농에 다른 첨가물 없이 건강한 맛이예요  \n",
       "52631  지인에게 받아 한봉 먹여봤는데 아기도 잘먹고 한입 쏙이라 손이 지저분해지지 않아 좋아요  \n",
       "52632                  소근육 발달에 좋대서 주문했는데 아기도 잘 먹고 좋아요^^  \n",
       "\n",
       "[52633 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
